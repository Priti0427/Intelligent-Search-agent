{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Search - Exploration Notebook\n",
    "\n",
    "This notebook explores the components of the Agentic Search system.\n",
    "\n",
    "## INFO 624: Intelligent Search and Language Models\n",
    "\n",
    "### Course Concepts Demonstrated:\n",
    "- Vector Space Models (Week 4)\n",
    "- Neural Language Models (Week 5)\n",
    "- Query Processing (Week 6)\n",
    "- Relevance Feedback (Week 9)\n",
    "- RAG Systems (Week 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "import asyncio\n",
    "from src.utils.config import get_settings\n",
    "\n",
    "settings = get_settings()\n",
    "print(f\"OpenAI configured: {bool(settings.openai_api_key)}\")\n",
    "print(f\"Tavily configured: {bool(settings.tavily_api_key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing Individual Retrievers\n",
    "\n",
    "Let's test each retriever independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Tavily Web Search\n",
    "from src.retrievers import get_tavily_retriever\n",
    "\n",
    "tavily = get_tavily_retriever()\n",
    "web_results = await tavily.search(\"What is RAG in AI?\")\n",
    "\n",
    "print(f\"Found {len(web_results)} web results\")\n",
    "for r in web_results[:3]:\n",
    "    print(f\"\\n- {r['title']}\")\n",
    "    print(f\"  URL: {r['url']}\")\n",
    "    print(f\"  Score: {r['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test arXiv Search\n",
    "from src.retrievers import get_arxiv_retriever\n",
    "\n",
    "arxiv = get_arxiv_retriever()\n",
    "arxiv_results = await arxiv.search(\"retrieval augmented generation\")\n",
    "\n",
    "print(f\"Found {len(arxiv_results)} academic papers\")\n",
    "for r in arxiv_results[:3]:\n",
    "    print(f\"\\n- {r['title']}\")\n",
    "    print(f\"  Authors: {r['metadata'].get('authors', 'N/A')}\")\n",
    "    print(f\"  URL: {r['url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Ingestion Pipeline\n",
    "\n",
    "Demonstrating text preprocessing and chunking (Week 2 concepts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test chunking strategies\n",
    "from src.ingestion import TextChunker, Document\n",
    "\n",
    "sample_text = \"\"\"\n",
    "# Information Retrieval\n",
    "\n",
    "Information retrieval (IR) is the process of obtaining information system resources \n",
    "that are relevant to an information need from a collection of those resources.\n",
    "\n",
    "## Vector Space Model\n",
    "\n",
    "The vector space model represents documents and queries as vectors in a \n",
    "high-dimensional space. Similarity is computed using cosine similarity.\n",
    "\n",
    "## BM25\n",
    "\n",
    "BM25 is a probabilistic retrieval function that ranks documents based on \n",
    "query terms appearing in each document.\n",
    "\"\"\"\n",
    "\n",
    "doc = Document(content=sample_text, metadata={\"title\": \"IR Overview\"})\n",
    "\n",
    "# Compare chunking strategies\n",
    "for strategy in [\"fixed\", \"paragraph\", \"semantic\"]:\n",
    "    chunker = TextChunker(strategy=strategy, chunk_size=200)\n",
    "    chunks = chunker.chunk_document(doc)\n",
    "    print(f\"\\n{strategy.upper()} chunking: {len(chunks)} chunks\")\n",
    "    for i, chunk in enumerate(chunks[:2]):\n",
    "        print(f\"  Chunk {i+1}: {len(chunk.content)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running the Full Agent\n",
    "\n",
    "Test the complete agentic search pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent import run_search\n",
    "\n",
    "# Simple query\n",
    "result = await run_search(\"What is RAG in AI?\")\n",
    "\n",
    "print(\"Query Type:\", result.get('query_type'))\n",
    "print(\"Sub-queries:\", [sq['query'] for sq in result.get('sub_queries', [])])\n",
    "print(\"\\nAnswer:\")\n",
    "print(result.get('final_answer', result.get('draft_answer', 'No answer'))[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex query with decomposition\n",
    "result = await run_search(\"Compare BM25 and dense retrieval for question answering\")\n",
    "\n",
    "print(\"Query Type:\", result.get('query_type'))\n",
    "print(\"\\nSub-queries:\")\n",
    "for sq in result.get('sub_queries', []):\n",
    "    print(f\"  - {sq['query']} -> {sq.get('sources', [])}\")\n",
    "\n",
    "print(\"\\nQuality Score:\", result.get('overall_quality', 0))\n",
    "print(\"Iterations:\", result.get('iteration_count', 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing the Agent Graph\n",
    "\n",
    "Visualize the LangGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent.graph import create_search_agent\n",
    "\n",
    "agent = create_search_agent()\n",
    "\n",
    "# Print graph structure\n",
    "print(\"Agent Graph Nodes:\")\n",
    "print(agent.get_graph().nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
